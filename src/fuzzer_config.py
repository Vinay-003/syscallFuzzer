#!/usr/bin/env python3
"""
fuzzer_config.py - Coverage-Guided Syscall Fuzzer with KCOV

FIXED VERSION with proper resource allocation for all sequences
Features:
- KCOV-based code coverage tracking
- Proper buffer and FD allocation for sequences
- Resource pool management for valid file descriptors
- Intelligent crash detection (distinguishes errors from crashes)
- Corpus management for interesting inputs
- Comprehensive logging and statistics
"""

import subprocess
import time
import os
import random
import re
import json
import signal
import sys
from datetime import datetime
from pathlib import Path
import shutil

# Import fuzzing logic
from fuzzer_brain import SYSCALL_SPECS, SYSCALL_SEQUENCES, TYPE_GENERATORS

# ============================================================================
# CONFIGURATION
# ============================================================================

class Config:
    """Central configuration for the fuzzer"""
    # VM Settings
    VM_DISK_IMAGE = "../alpine.qcow2"
    VM_RAM = "1G"
    HOST_SSH_PORT = "10022"
    VM_USER = "root"
    VM_PASSWORD = "123"
    
    # Paths
    EXECUTOR_SOURCE = "executor.c"
    EXECUTOR_VM_PATH = "/root/executor"
    CRASHES_DIR = "crashes"
    CORPUS_DIR = "corpus"
    
    # Timeouts (seconds)
    VM_BOOT_TIMEOUT = 60
    SSH_READY_TIMEOUT = 30
    SSH_COMMAND_TIMEOUT = 20
    VM_SHUTDOWN_TIMEOUT = 30
    
    # Fuzzing behavior
    SEQUENCE_PROBABILITY = 0.3  # 30% chance to run sequence vs single syscall
    ITERATION_DELAY = 0.05  # seconds between iterations
    MAX_ITERATIONS_PER_SESSION = 1000  # Restart VM after this many iterations
    
    # Coverage thresholds
    MIN_INTERESTING_COVERAGE = 5  # Minimum coverage to be considered interesting
    
    # Resource allocation sizes
    BUFFER_SIZE = 65536  # 64KB buffer for various operations
    PIPE_FD_ARRAY_SIZE = 8  # Space for pipe FD pairs
    
    @staticmethod
    def get_qemu_command():
        """Generate QEMU command with optimal settings"""
        return [
            "qemu-system-x86_64",
            "-m", Config.VM_RAM,
            "-hda", Config.VM_DISK_IMAGE,
            "-nographic",
            "-netdev", f"user,id=net0,hostfwd=tcp::{Config.HOST_SSH_PORT}-:22",
            "-device", "e1000,netdev=net0",
            "-enable-kvm"  # Use KVM for better performance
        ]


# ============================================================================
# CRASH LOGGING
# ============================================================================

class CrashLogger:
    """Handles crash detection and artifact collection"""
    
    def __init__(self, crashes_dir):
        self.crashes_dir = Path(crashes_dir)
        self.crashes_dir.mkdir(exist_ok=True)
        self.crash_count = 0
    
    def log_crash(self, reproducer_commands, crash_context=None, console_log_path=None):
        """
        Save comprehensive crash information
        
        Args:
            reproducer_commands: Command(s) that caused the crash
            crash_context: Additional context (dict with metadata)
            console_log_path: Path to the VM's console log file
        
        Returns:
            Path to crash directory
        """
        self.crash_count += 1
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S_%f")
        crash_dir = self.crashes_dir / f"crash_{timestamp}"
        crash_dir.mkdir(exist_ok=True)
        
        print("\n" + "!" * 70)
        print(f"{'⚠️  POTENTIAL CRASH DETECTED  ⚠️':^70}")
        print(f"{'Saving to: ' + str(crash_dir):^70}")
        print("!" * 70)
        
        # Save reproducer script
        reproducer_file = crash_dir / "reproducer.sh"
        with open(reproducer_file, "w") as f:
            f.write("#!/bin/bash\n")
            f.write("# Crash reproducer generated by syscall fuzzer\n")
            f.write(f"# Timestamp: {timestamp}\n")
            f.write(f"# Crash #{self.crash_count}\n\n")
            
            if isinstance(reproducer_commands, (list, tuple)):
                for cmd in reproducer_commands:
                    f.write(f"{cmd}\n")
            else:
                f.write(f"{reproducer_commands}\n")
        
        reproducer_file.chmod(0o755)
        
        # Save metadata
        metadata = {
            "timestamp": timestamp,
            "crash_number": self.crash_count,
            "commands": reproducer_commands if isinstance(reproducer_commands, list) else [reproducer_commands],
            "crash_context": crash_context or {}
        }
        
        with open(crash_dir / "metadata.json", "w") as f:
            json.dump(metadata, f, indent=2)
        
        # Save summary
        with open(crash_dir / "crash_summary.txt", "w") as f:
            f.write("=== Syscall Fuzzer Crash Report ===\n")
            f.write(f"Timestamp: {timestamp}\n")
            f.write(f"Crash Number: #{self.crash_count}\n")
            f.write(f"Crash Directory: {crash_dir}\n\n")
            
            f.write("--- Reproducer Commands ---\n")
            if isinstance(reproducer_commands, (list, tuple)):
                for i, cmd in enumerate(reproducer_commands, 1):
                    f.write(f"{i}. {cmd}\n")
            else:
                f.write(f"{reproducer_commands}\n")
            
            if crash_context:
                f.write("\n--- Additional Context ---\n")
                for key, value in crash_context.items():
                    f.write(f"{key}: {value}\n")

        # Copy console log for kernel panic analysis
        if console_log_path and console_log_path.exists():
            try:
                shutil.copy(console_log_path, crash_dir / "console.log")
                print(f"[+] Saved VM console log")
            except Exception as e:
                print(f"[!] Failed to copy console log: {e}")
        
        print(f"[+] Crash artifacts saved to: {crash_dir}")
        return crash_dir


# ============================================================================
# SSH OPERATIONS
# ============================================================================

class SSHRunner:
    """Handles SSH communication with the VM"""
    
    def __init__(self, host="localhost", port=None, user=None, password=None):
        self.host = host
        self.port = port or Config.HOST_SSH_PORT
        self.user = user or Config.VM_USER
        self.password = password or Config.VM_PASSWORD
        self.ssh_base_opts = [
            "-o", "StrictHostKeyChecking=no",
            "-o", "UserKnownHostsFile=/dev/null",
            "-o", "ConnectTimeout=10",
            "-o", "LogLevel=ERROR"
        ]
    
    def check_ssh_ready(self):
        """Check if SSH port is accepting connections"""
        try:
            result = subprocess.run(
                ["nc", "-z", self.host, self.port],
                timeout=2,
                capture_output=True
            )
            return result.returncode == 0
        except (subprocess.TimeoutExpired, subprocess.CalledProcessError, FileNotFoundError):
            return False
    
    def run_command(self, command, suppress_errors=False, timeout=None):
        """
        Execute command in VM via SSH
        
        Returns:
            CompletedProcess on success, None on failure/timeout
        """
        timeout = timeout or Config.SSH_COMMAND_TIMEOUT
        
        ssh_cmd = [
            "sshpass", "-p", self.password,
            "ssh", f"{self.user}@{self.host}",
            "-p", self.port
        ] + self.ssh_base_opts + [command]
        
        try:
            if not suppress_errors:
                print(f"[VM] {command}")
            
            result = subprocess.run(
                ssh_cmd,
                capture_output=True,
                text=True,
                timeout=timeout
            )
            
            # Return result regardless of exit code - let caller decide
            if not suppress_errors and result.stdout.strip():
                print(f"[OUTPUT] {result.stdout.strip()}")
            
            return result
                
        except subprocess.TimeoutExpired:
            if not suppress_errors:
                print(f"[!] Command timed out after {timeout}s")
            return None
        except Exception as e:
            if not suppress_errors:
                print(f"[!] SSH error: {e}")
            return None
    
    def transfer_file(self, local_path, remote_path):
        """Copy file from host to VM"""
        print(f"[*] Transfer: {local_path} → VM:{remote_path}")
        
        scp_cmd = [
            "sshpass", "-p", self.password,
            "scp", "-P", self.port
        ] + self.ssh_base_opts + [
            local_path,
            f"{self.user}@{self.host}:{remote_path}"
        ]
        
        try:
            subprocess.run(scp_cmd, check=True, capture_output=True, timeout=30)
            print("[+] Transfer successful")
            return True
        except (subprocess.CalledProcessError, subprocess.TimeoutExpired) as e:
            print(f"[!] Transfer failed: {e}")
            return False


# ============================================================================
# VM MANAGEMENT
# ============================================================================

class VMManager:
    """Manages QEMU VM lifecycle"""
    
    def __init__(self, ssh_runner):
        self.ssh_runner = ssh_runner
        self.vm_process = None
        self.console_log_path = Path("console.log")
        self.console_log_file = None
    
    def start_vm(self):
        """Start VM and wait for SSH readiness"""
        print("\n[*] Starting VM...")
        
        try:
            # Open console log for capturing kernel messages
            self.console_log_file = open(self.console_log_path, "wb")
            self.vm_process = subprocess.Popen(
                Config.get_qemu_command(),
                stdout=self.console_log_file,
                stderr=self.console_log_file
            )
        except Exception as e:
            print(f"[!] Failed to start VM: {e}")
            if self.console_log_file:
                self.console_log_file.close()
            return False
        
        print(f"[+] VM started (PID: {self.vm_process.pid})")
        
        # Wait for SSH port to open
        print("[*] Waiting for SSH port...")
        start_time = time.time()
        
        while time.time() - start_time < Config.VM_BOOT_TIMEOUT:
            if self.ssh_runner.check_ssh_ready():
                print("[+] SSH port open")
                time.sleep(5)  # Let SSH service fully initialize
                
                # Verify SSH is actually responsive
                if self._verify_ssh_responsive():
                    print("[+] VM ready for fuzzing")
                    return True
                
            time.sleep(1)
        
        print("[!] VM boot timeout")
        self.terminate_vm()
        return False
    
    def _verify_ssh_responsive(self):
        """Verify SSH is actually responsive"""
        print("[*] Verifying SSH responsiveness...")
        
        start_time = time.time()
        while time.time() - start_time < Config.SSH_READY_TIMEOUT:
            result = self.ssh_runner.run_command(
                "echo SSH_OK",
                suppress_errors=True
            )
            
            if result and result.returncode == 0 and "SSH_OK" in (result.stdout or ""):
                return True
            
            time.sleep(2)
        
        return False
    
    def shutdown_vm(self, force=False):
        """Gracefully shutdown VM"""
        if not self.vm_process:
            if self.console_log_file:
                self.console_log_file.close()
            return
        
        if force:
            print("[*] Force terminating VM...")
            self.vm_process.terminate()
        else:
            print("[*] Shutting down VM gracefully...")
            self.ssh_runner.run_command("poweroff", suppress_errors=True, timeout=10)
            
            try:
                self.vm_process.wait(timeout=Config.VM_SHUTDOWN_TIMEOUT)
            except subprocess.TimeoutExpired:
                print("[!] Graceful shutdown timeout, forcing...")
                self.vm_process.terminate()
        
        if self.console_log_file:
            self.console_log_file.close()
        self.vm_process = None
        print("[+] VM stopped")
    
    def terminate_vm(self):
        """Immediately terminate VM"""
        self.shutdown_vm(force=True)
    
    def is_running(self):
        """Check if VM is still running"""
        if not self.vm_process:
            return False
        return self.vm_process.poll() is None
    
    def check_for_kernel_panic(self):
        """
        Check console log for kernel panic indicators
        
        Returns:
            True if panic detected, False otherwise
        """
        if not self.console_log_path.exists():
            return False
        
        try:
            with open(self.console_log_path, 'rb') as f:
                content = f.read().decode('utf-8', errors='ignore')
                
            # Common kernel panic indicators
            panic_indicators = [
    # Core panic messages
    "Kernel panic",
    "Kernel Panic",
    "kernel panic - not syncing",
    "not syncing:",
    "Attempted to kill init!",
    "Fatal exception",

    # General protection and fault errors
    "general protection fault",
    "unable to handle kernel",
    "page fault in",
    "Segmentation fault",
    "Oops:",
    "BUG:",
    "BUG: kernel NULL pointer dereference",
    "kernel BUG at",

    # Memory corruption and safety mechanisms
    "KASAN:",
    "KMSAN:",
    "KCSAN:",
    "UBSAN:",
    "lockdep:",
    "RCU stall",
    "watchdog: BUG",
    "watchdog: BUG: soft lockup",
    "watchdog: BUG: hard LOCKUP",
    "soft lockup - CPU",
    "hard LOCKUP",
    "hung task",
    "task hung",
    "WARNING: CPU:",
    "stack segment:",
    "stack overflow in",
    "bad stack state",

    # Filesystem / block-level panics
    "EXT4-fs error",
    "XFS (",
    "BTRFS critical",
    "FAT-fs (",
    "I/O error",
    "end_request: I/O error",
    "Buffer I/O error",

    # Architecture / CPU-specific fatal errors
    "Machine check",
    "Machine check events logged",
    "Internal error:",
    "Illegal instruction",
    "Bad page state",
    "bad paging request",
    "bad kernel paging request",
    "Unable to handle kernel paging request",
    "Instruction fetch fault",
    "Double fault",
    "Triple fault",

    # Module or driver fatal issues
    "Fatal signal",
    "kernel NULL pointer dereference",
    "BUG: unable to handle page fault",
    "Modules linked in:",
]

            
            return any(indicator.lower() in content.lower() for indicator in panic_indicators)
        except Exception:
            return False


# ============================================================================
# FUZZING ENGINE WITH PROPER RESOURCE ALLOCATION
# ============================================================================

class FuzzingEngine:
    """Core fuzzing logic with KCOV coverage tracking and resource management"""
    
    # Regex to parse executor output with coverage
    RE_EXECUTOR_OUTPUT = re.compile(
        r"syscall\((\d+)\)\s*=\s*(-?\d+)(?:.*?coverage=(\d+))?"
    )
    
    def __init__(self, ssh_runner, crash_logger, vm_manager):
        self.ssh_runner = ssh_runner
        self.crash_logger = crash_logger
        self.vm_manager = vm_manager
        self.iteration = 0
        
        # Coverage tracking - store sets of unique PCs (program counters)
        self.coverage_map = {}  # Maps coverage count to set of inputs
        self.total_coverage = set()  # All unique coverage counts seen
        
        # Corpus management
        self.corpus_dir = Path(Config.CORPUS_DIR)
        self.corpus_dir.mkdir(exist_ok=True)
        
        # Resource pool for valid file descriptors and buffers
        self.resource_pool = {
            "fd": [],  # Valid file descriptors
            "valid_buffer": None,  # Allocated buffer address
            "pipe_fds": None,  # Pipe FD array address
            "timer_id_buffer": None,  # Timer ID buffer
        }
        
        # Statistics
        self.stats = {
            "total_syscalls": 0,
            "total_sequences": 0,
            "errors": 0,  # Expected errors (ENOENT, EINVAL, etc.)
            "crashes": 0,  # Actual crashes/panics
            "new_coverage": 0,
            "iterations": 0
        }
        
        print("[*] Fuzzing engine initialized")
        print(f"[*] Corpus directory: {self.corpus_dir}")
    
    def allocate_resources(self):
        """
        Allocate persistent resources needed for sequences
        Returns True on success, False on failure
        """
        print("\n[*] Allocating fuzzing resources...")
        
        # Allocate main buffer using mmap
        print(f"[*] Allocating {Config.BUFFER_SIZE} byte buffer...")
        status, buffer_addr, coverage = self.execute_syscall(
            "mmap",
            ["0", str(Config.BUFFER_SIZE), "3", "34", "-1", "0"],  # PROT_READ|WRITE, MAP_PRIVATE|ANON
            check_crash=False
        )
        
        if status == 'success' and buffer_addr and buffer_addr > 0:
            self.resource_pool["valid_buffer"] = buffer_addr
            print(f"[+] Buffer allocated at 0x{buffer_addr:x}")
            
            # Write some data to the buffer
            self.ssh_runner.run_command(
                f"echo 'user.test' | dd of=/proc/self/mem bs=1 count=10 seek={buffer_addr} 2>/dev/null || true",
                suppress_errors=True
            )
        else:
            print("[!] Failed to allocate main buffer")
            return False
        
        # Allocate pipe FD array buffer
        print(f"[*] Allocating pipe FD array...")
        status, pipe_fds_addr, coverage = self.execute_syscall(
            "mmap",
            ["0", str(Config.PIPE_FD_ARRAY_SIZE), "3", "34", "-1", "0"],
            check_crash=False
        )
        
        if status == 'success' and pipe_fds_addr and pipe_fds_addr > 0:
            self.resource_pool["pipe_fds"] = pipe_fds_addr
            print(f"[+] Pipe FD array allocated at 0x{pipe_fds_addr:x}")
        else:
            print("[!] Warning: Failed to allocate pipe FD array")
        
        # Allocate timer ID buffer
        status, timer_buf_addr, coverage = self.execute_syscall(
            "mmap",
            ["0", "16", "3", "34", "-1", "0"],
            check_crash=False
        )
        
        if status == 'success' and timer_buf_addr and timer_buf_addr > 0:
            self.resource_pool["timer_id_buffer"] = timer_buf_addr
            print(f"[+] Timer ID buffer allocated at 0x{timer_buf_addr:x}")
        
        # Open some file descriptors to populate the FD pool
        print("[*] Creating initial file descriptors...")
        for path in ["/tmp/fuzzfile", "/tmp/testfile"]:
            status, fd, coverage = self.execute_syscall(
                "open",
                [path, "66", "420"],  # O_RDWR|O_CREAT, 0644
                check_crash=False
            )
            if status == 'success' and fd and fd >= 0:
                self.resource_pool["fd"].append(fd)
                print(f"[+] Created FD {fd} for {path}")
        
        # Open /dev/null and /dev/zero
        for path in ["/dev/null", "/dev/zero"]:
            status, fd, coverage = self.execute_syscall(
                "open",
                [path, "2", "0"],  # O_RDWR
                check_crash=False
            )
            if status == 'success' and fd and fd >= 0:
                self.resource_pool["fd"].append(fd)
                print(f"[+] Opened FD {fd} for {path}")
        
        print(f"[+] Resource allocation complete!")
        print(f"    - Buffer: 0x{self.resource_pool['valid_buffer']:x}")
        print(f"    - Pipe FDs: 0x{self.resource_pool.get('pipe_fds', 0):x}")
        print(f"    - Valid FDs: {len(self.resource_pool['fd'])} descriptors")
        
        return True
    
    def parse_executor_output(self, stdout):
        """
        Extract syscall return value and coverage from executor output
        
        Returns:
            (return_value: int or None, coverage_count: int or None)
        """
        if not stdout:
            return None, None
        
        match = self.RE_EXECUTOR_OUTPUT.search(stdout)
        if match:
            try:
                ret_val = int(match.group(2))
                coverage = int(match.group(3)) if match.group(3) else None
                return ret_val, coverage
            except (ValueError, IndexError):
                return None, None
        return None, None
    
    def is_interesting_coverage(self, coverage_count):
        """
        Determine if coverage count represents new/interesting code paths
        
        Args:
            coverage_count: Number of unique PCs covered
            
        Returns:
            True if this is new or interesting coverage
        """
        if coverage_count is None or coverage_count < Config.MIN_INTERESTING_COVERAGE:
            return False
        
        # New coverage count we haven't seen before
        if coverage_count not in self.total_coverage:
            return True
        
        return False
    
    def save_to_corpus(self, command, coverage_count):
        """Save interesting input to corpus"""
        filename = self.corpus_dir / f"cov_{coverage_count}_iter_{self.iteration}"
        
        try:
            with open(filename, "w") as f:
                f.write(command)
            print(f"[+] Saved to corpus: {filename.name}")
            return True
        except Exception as e:
            print(f"[!] Failed to save to corpus: {e}")
            return False
    
    def update_resource_pool(self, syscall_name, ret_val):
        """
        Update resource pool with valid resources created by syscalls
        
        Args:
            syscall_name: Name of the syscall executed
            ret_val: Return value from the syscall
        """
        # File descriptor-creating syscalls
        fd_creating_syscalls = [
            "open", "openat", "socket", "epoll_create", "epoll_create1",
            "eventfd", "eventfd2", "timerfd_create", "signalfd", "signalfd4",
            "memfd_create", "userfaultfd", "pipe", "pipe2", "dup", "dup2", "dup3",
            "inotify_init", "inotify_init1", "fanotify_init", "perf_event_open",
            "io_uring_setup", "pidfd_open"
        ]
        
        if syscall_name in fd_creating_syscalls and ret_val is not None and ret_val >= 0:
            # Valid FD created
            if ret_val not in self.resource_pool["fd"]:
                self.resource_pool["fd"].append(ret_val)
                print(f"[+] Added FD {ret_val} to resource pool (total: {len(self.resource_pool['fd'])})")
                
                # Keep pool size reasonable
                if len(self.resource_pool["fd"]) > 30:
                    removed = self.resource_pool["fd"].pop(0)
                    print(f"[*] Removed old FD {removed} from pool")
    
    def resolve_argument(self, arg_spec, env):
        """
        Resolve argument specification to concrete value
        
        Args:
            arg_spec: Argument specification (string, dict, or literal)
            env: Environment dict with stored results from sequence execution
        
        Returns:
            String representation of the argument value
        """
        # Handle literal value from sequence (e.g., {'literal': 123})
        if isinstance(arg_spec, dict) and "literal" in arg_spec:
            return str(arg_spec["literal"])
        
        # Handle environment variable reference (e.g., {'value': 'fd1'})
        if isinstance(arg_spec, dict) and "value" in arg_spec:
            var_name = arg_spec["value"]
            
            # Check for special resource pool variables
            if var_name == "valid_buffer":
                return str(self.resource_pool.get("valid_buffer", 0))
            elif var_name == "pipe_fds":
                return str(self.resource_pool.get("pipe_fds", 0))
            elif var_name == "timer_id_buffer":
                return str(self.resource_pool.get("timer_id_buffer", 0))
            # Handle pipe FD extraction (pipe_read_fd, pipe_write_fd)
            elif var_name == "pipe_read_fd":
                # Read FD is at pipe_fds[0]
                return str(env.get("pipe_read_fd", env.get("pipe_fd", 3)))
            elif var_name == "pipe_write_fd":
                # Write FD is at pipe_fds[1]
                return str(env.get("pipe_write_fd", env.get("pipe_fd", 4)))
            # Handle socketpair FD extraction
            elif var_name == "socket_fd1":
                return str(env.get("socket_fd1", env.get("socket_fd", 3)))
            elif var_name == "socket_fd2":
                return str(env.get("socket_fd2", env.get("socket_fd", 4)))
            
            return str(env.get(var_name, 0))
        
        # Handle type generator
        if isinstance(arg_spec, str):
            # Special handling for valid_fd - use resource pool
            if arg_spec == "valid_fd":
                if self.resource_pool["fd"]:
                    chosen_fd = random.choice(self.resource_pool["fd"])
                    return str(chosen_fd)
                else:
                    # Pool empty, return a common FD
                    return "3"
            
            # Special handling for valid_buffer
            if arg_spec == "valid_buffer":
                return str(self.resource_pool.get("valid_buffer", 0))
            
            # Special handling for pipe_fds
            if arg_spec == "pipe_fds":
                return str(self.resource_pool.get("pipe_fds", 0))
            
            # Check if it's an environment variable
            if arg_spec in env:
                return str(env[arg_spec])
            
            # Check if it's a generator type
            generator = TYPE_GENERATORS.get(arg_spec)
            if generator:
                try:
                    return str(generator())
                except Exception:
                    return "0"
            
            # Return as-is (literal string or path)
            return arg_spec
        
        # Return literal value
        return str(arg_spec)
    
    def generate_random_syscall(self):
        """Generate a random syscall with arguments"""
        syscall_name = random.choice(list(SYSCALL_SPECS.keys()))
        arg_types = SYSCALL_SPECS[syscall_name]
        args = [self.resolve_argument(arg_type, {}) for arg_type in arg_types]
        return syscall_name, args
    
    def execute_syscall(self, syscall_name, args, check_crash=True):
        """
        Execute a single syscall
        
        Args:
            syscall_name: Name of the syscall
            args: List of argument values
            check_crash: Whether to check for crashes
        
        Returns:
            (status: str, return_value: int or None, coverage: int or None)
            status can be: 'success', 'error', 'timeout', 'crash'
        """
        command = f"{Config.EXECUTOR_VM_PATH} {syscall_name} {' '.join(args)}"
        result = self.ssh_runner.run_command(command, suppress_errors=True)
        
        # Check for timeout (potential hang/crash)
        if result is None:
            if check_crash and self.vm_manager.check_for_kernel_panic():
                return 'crash', None, None
            return 'timeout', None, None
        
        # Parse output
        ret_val, coverage = self.parse_executor_output(result.stdout)
        
        # Update resource pool if syscall succeeded
        if ret_val is not None and ret_val >= 0:
            self.update_resource_pool(syscall_name, ret_val)
        
        # Determine status
        if result.returncode != 0:
            # Non-zero exit could be normal (syscall returned error)
            # or could indicate executor crash
            if "Error:" in result.stderr or result.returncode == 124:
                return 'timeout', ret_val, coverage
            elif check_crash and self.vm_manager.check_for_kernel_panic():
                return 'crash', ret_val, coverage
            else:
                # Likely just a syscall that returned an error
                return 'error', ret_val, coverage
        
        return 'success', ret_val, coverage
    
    def execute_sequence(self, sequence_name, steps):
        """
        Execute a sequence of syscalls with environment tracking
        
        Returns:
            (status: str, commands_executed: list)
        """
        print(f"\n[*] Executing sequence: {sequence_name}")
        
        env = {}  # Environment for storing intermediate results
        commands = []
        
        # Special handling for pipe/socketpair sequences
        # Pre-populate env with expected FD values
        if "pipe" in sequence_name or "splice" in sequence_name:
            env["pipe_read_fd"] = 3  # Typical first available FD
            env["pipe_write_fd"] = 4
        if "socketpair" in sequence_name:
            env["socket_fd1"] = 3
            env["socket_fd2"] = 4
        
        for step_num, step in enumerate(steps, 1):
            syscall_name = step.get("action") or step.get("name")
            arg_specs = step.get("args", [])
            
            # Resolve arguments using environment
            args = [self.resolve_argument(spec, env) for spec in arg_specs]
            
            # Build command string
            command = f"{Config.EXECUTOR_VM_PATH} {syscall_name} {' '.join(args)}"
            commands.append(command)
            
            print(f"  [{step_num}/{len(steps)}] {syscall_name}({', '.join(args)})")
            
            # Execute syscall
            status, ret_val, coverage = self.execute_syscall(syscall_name, args, check_crash=True)
            
            # Handle result
            if status == 'crash':
                print(f"  [!] Crash detected at step {step_num}")
                return 'crash', commands
            elif status == 'timeout':
                print(f"  [!] Timeout at step {step_num}")
                # Continue sequence even on timeout (might be interesting)
            
            # Store return value in environment if requested
            if step.get("result"):
                result_var = step["result"]
                env[result_var] = ret_val if ret_val is not None else -1
                print(f"    → {result_var} = {env[result_var]}")
                
                # Special handling for pipe() - extract both FDs
                if syscall_name in ["pipe", "pipe2"] and ret_val == 0:
                    # pipe() returns 0 on success, FDs are written to the array
                    # We'll simulate this by assigning sequential FDs
                    env["pipe_read_fd"] = 3  # Assume first available FD
                    env["pipe_write_fd"] = 4
                    print(f"    → pipe_read_fd = {env['pipe_read_fd']}")
                    print(f"    → pipe_write_fd = {env['pipe_write_fd']}")
                
                ## Special handling for socketpair() - extract both FDs
                if syscall_name == "socketpair" and ret_val == 0:
                    # socketpair() returns 0 on success, FDs are written to the array
                    env["socket_fd1"] = 3  # Assume first available FD
                    env["socket_fd2"] = 4
                    print(f"    → socket_fd1 = {env['socket_fd1']}")
                    print(f"    → socket_fd2 = {env['socket_fd2']}")
        
        print(f"[+] Sequence '{sequence_name}' completed")
        return 'success', commands
    
    def run_iteration(self):
        """
        Run a single fuzzing iteration
        
        Returns:
            bool: True if should continue, False if crash detected
        """
        self.iteration += 1
        self.stats["iterations"] += 1
        
        print(f"\n{'=' * 70}")
        print(f"Iteration #{self.iteration}")
        print('=' * 70)
        
        # Decide: single syscall or sequence?
        run_sequence = (
            random.random() < Config.SEQUENCE_PROBABILITY and 
            SYSCALL_SEQUENCES
        )
        
        if run_sequence:
            # Execute sequence
            sequence_name, steps = random.choice(list(SYSCALL_SEQUENCES.items()))
            status, commands = self.execute_sequence(sequence_name, steps)
            
            self.stats["total_sequences"] += 1
            self.stats["total_syscalls"] += len(steps)
            
            if status == 'crash':
                # Real crash detected
                self.stats["crashes"] += 1
                crash_dir = self.crash_logger.log_crash(
                    commands,
                    crash_context={
                        "type": "sequence",
                        "sequence_name": sequence_name,
                        "iteration": self.iteration,
                        "stats": self.stats.copy()
                    },
                    console_log_path=self.vm_manager.console_log_path
                )
                return False  # Stop this session
            elif status in ('timeout', 'error'):
                self.stats["errors"] += 1
        
        else:
            # Execute single syscall
            syscall_name, args = self.generate_random_syscall()
            command = f"{Config.EXECUTOR_VM_PATH} {syscall_name} {' '.join(args)}"
            
            print(f"[*] Testing: {syscall_name}({', '.join(args)})")
            
            status, ret_val, coverage = self.execute_syscall(syscall_name, args, check_crash=True)
            
            self.stats["total_syscalls"] += 1
            
            # Handle crash
            if status == 'crash':
                self.stats["crashes"] += 1
                crash_dir = self.crash_logger.log_crash(
                    command,
                    crash_context={
                        "type": "single",
                        "syscall": syscall_name,
                        "args": args,
                        "iteration": self.iteration,
                        "coverage": coverage,
                        "stats": self.stats.copy()
                    },
                    console_log_path=self.vm_manager.console_log_path
                )
                return False  # Stop this session
            
            # Handle error (expected syscall failures)
            elif status == 'error':
                self.stats["errors"] += 1
                print(f"[*] Syscall returned error (expected)")
            
            # Handle success with coverage
            elif status == 'success' and coverage is not None:
                print(f"[+] Return: {ret_val} | Coverage: {coverage} PCs")
                
                # Check if coverage is interesting
                if self.is_interesting_coverage(coverage):
                    print(f"\n{'*' * 25} NEW COVERAGE! {'*' * 25}")
                    self.total_coverage.add(coverage)
                    self.stats["new_coverage"] += 1
                    self.save_to_corpus(command, coverage)
        
        return True  # Continue fuzzing
    
    def run_session(self):
        """
        Run a complete fuzzing session until crash, max iterations, or interruption
        
        Returns:
            str: 'interrupted', 'crash', or 'max_iterations'
        """
        print("\n" + "#" * 70)
        print(f"{'FUZZING SESSION START':^70}")
        print("#" * 70)
        
        # Allocate resources before fuzzing
        if not self.allocate_resources():
            print("[!] Failed to allocate resources")
            return 'error'
        
        session_start = time.time()
        
        try:
            while self.iteration < Config.MAX_ITERATIONS_PER_SESSION:
                should_continue = self.run_iteration()
                
                if not should_continue:
                    # Crash detected
                    return 'crash'
                
                time.sleep(Config.ITERATION_DELAY)
            
            # Reached max iterations
            return 'max_iterations'
                
        except KeyboardInterrupt:
            print("\n[!] Session interrupted by user")
            return 'interrupted'
    
    def print_stats(self):
        """Print comprehensive fuzzing statistics"""
        print("\n" + "=" * 70)
        print("FUZZING STATISTICS")
        print("=" * 70)
        print(f"Total Iterations:      {self.stats['iterations']}")
        print(f"Total Syscalls:        {self.stats['total_syscalls']}")
        print(f"Total Sequences:       {self.stats['total_sequences']}")
        print(f"Expected Errors:       {self.stats['errors']}")
        print(f"Crashes Found:         {self.stats['crashes']}")
        print(f"New Coverage Found:    {self.stats['new_coverage']}")
        print(f"Total Unique Coverage: {len(self.total_coverage)}")
        print(f"Resource Pool (FDs):   {len(self.resource_pool['fd'])}")
        print("=" * 70)


# ============================================================================
# SETUP AND INITIALIZATION
# ============================================================================

def setup_executor(ssh_runner):
    """Transfer and compile executor in VM, setup KCOV"""
    print("\n" + "=" * 70)
    print("EXECUTOR SETUP")
    print("=" * 70)
    
    # Create test files in VM
    print("[*] Creating test files...")
    ssh_runner.run_command("touch /tmp/fuzzfile /tmp/testfile")
    ssh_runner.run_command("chmod 666 /tmp/fuzzfile /tmp/testfile")
    
    # Mount debugfs for KCOV
    print("[*] Mounting debugfs for KCOV...")
    result = ssh_runner.run_command(
        "mountpoint -q /sys/kernel/debug || mount -t debugfs none /sys/kernel/debug"
    )
    if not result or result.returncode != 0:
        print("[!] Warning: Could not mount debugfs (KCOV may not work)")
    
    # Verify KCOV is available
    print("[*] Verifying KCOV availability...")
    result = ssh_runner.run_command(
        "test -e /sys/kernel/debug/kcov && echo 'KCOV_OK'",
        suppress_errors=True
    )
    if not result or "KCOV_OK" not in result.stdout:
        print("[!] Warning: KCOV not available - coverage tracking will not work")
        print("[!] Make sure you compiled the kernel with KCOV support")
    else:
        print("[+] KCOV is available")
    
    # Transfer source
    if not ssh_runner.transfer_file(Config.EXECUTOR_SOURCE, "/root/executor.c"):
        print("[!] Failed to transfer executor source")
        return False
    
    # Install build tools if needed
    print("[*] Installing build tools...")
    result = ssh_runner.run_command(
        "which gcc || apk add --no-cache build-base",
        timeout=120
    )
    if not result:
        print("[!] Failed to install build tools")
        return False
    
    # Compile executor
    print("[*] Compiling executor...")
    result = ssh_runner.run_command(
        f"gcc -O2 -Wall /root/executor.c -o {Config.EXECUTOR_VM_PATH}",
        timeout=60
    )
    if not result or result.returncode != 0:
        print("[!] Compilation failed")
        if result:
            print(f"[!] Error: {result.stderr}")
        return False
    
    # Verify executable exists
    result = ssh_runner.run_command(
        f"test -x {Config.EXECUTOR_VM_PATH} && echo 'EXECUTOR_OK'",
        suppress_errors=True
    )
    if not result or "EXECUTOR_OK" not in result.stdout:
        print("[!] Executor not found after compilation")
        return False
    
    print("[+] Executor ready")
    return True


# ============================================================================
# MAIN ORCHESTRATION
# ============================================================================

def main():
    """Main fuzzer orchestration"""
    print("\n" + "#" * 70)
    print(f"{'COVERAGE-GUIDED SYSCALL FUZZER':^70}")
    print(f"{'WITH PROPER RESOURCE ALLOCATION':^70}")
    print("#" * 70)
    
    # Initialize random seed
    seed = int(time.time() * 1000) & 0xFFFFFFFF
    random.seed(seed)
    print(f"[*] Random seed: {seed}")
    
    # Initialize components
    ssh_runner = SSHRunner()
    vm_manager = VMManager(ssh_runner)
    crash_logger = CrashLogger(Config.CRASHES_DIR)
    
    # Initial setup - start VM once to compile executor
    print("\n[*] Performing initial setup...")
    if not vm_manager.start_vm():
        print("[!] Initial VM startup failed")
        return 1
    
    if not setup_executor(ssh_runner):
        print("[!] Executor setup failed")
        vm_manager.terminate_vm()
        return 1
    
    # Shutdown VM for clean fuzzing sessions
    print("[*] Setup complete, shutting down for clean sessions...")
    vm_manager.shutdown_vm()
    time.sleep(3)
    
    # Main fuzzing loop
    print("\n" + "#" * 70)
    print(f"{'READY TO FUZZ':^70}")
    print("#" * 70)
    
    # Create fuzzing engine (persistent across sessions)
    fuzzing_engine = FuzzingEngine(ssh_runner, crash_logger, vm_manager)
    session_count = 0
    
    try:
        while True:
            session_count += 1
            print(f"\n{'#' * 70}")
            print(f"{'FUZZING SESSION #' + str(session_count):^70}")
            print(f"{'#' * 70}")
            
            # Start fresh VM for this session
            if not vm_manager.start_vm():
                print("[!] Failed to start VM")
                break
            
            # Run fuzzing session
            result = fuzzing_engine.run_session()
            
            # Print statistics after each session
            fuzzing_engine.print_stats()
            
            # Handle session result
            if result == 'interrupted':
                print("[*] User requested shutdown")
                vm_manager.shutdown_vm()
                break
            elif result == 'crash':
                print("[*] Crash detected - restarting VM for next session")
                vm_manager.terminate_vm()
                time.sleep(3)
            elif result == 'max_iterations':
                print("[*] Max iterations reached - restarting VM for fresh session")
                vm_manager.shutdown_vm()
                time.sleep(3)
            elif result == 'error':
                print("[!] Resource allocation error - restarting VM")
                vm_manager.terminate_vm()
                time.sleep(3)
    
    except KeyboardInterrupt:
        print("\n\n[!] Fuzzer interrupted by user")
    except Exception as e:
        print(f"\n[!] Unexpected error: {e}")
        import traceback
        traceback.print_exc()
    finally:
        print("\n[*] Cleaning up...")
        vm_manager.terminate_vm()
        fuzzing_engine.print_stats()
        print("[+] Fuzzer shutdown complete")
        print(f"\n[*] Total sessions run: {session_count}")
        print(f"[*] Check '{Config.CRASHES_DIR}' for crash reports")
        print(f"[*] Check '{Config.CORPUS_DIR}' for interesting inputs")
    
    return 0


if __name__ == "__main__":
    sys.exit(main())